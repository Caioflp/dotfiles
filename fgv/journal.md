# Undergraduate Thesis

## 04.02.23.

* Fumbled around a bit trying to figure out what to do with respect
  to my undergrad thesis, found out I really need to revise functional
  analysis. Will try to read the Nesterov papers yuri suggested me and
  take notes.
* The Landweber iteration is basically Gradient Descent on Hilbert
  spaces.
* Articles cited by chinese guy addressed problems in which the
  forward operator is non-linear and, hence, the loss function is
  non-convex. From what I could gather one technique that stands out,
  particularly in convex problems, is Nesterov Acceleration. However,
  every description I've seen of it is different from what is presented
  Nesterov's original 1983 paper. Will try to read and understand
  Nesterov's proof of convergence for his algorithm and how to apply it
  to linear SIP's.

## 05.02.23.

* Read the first 8 pages of Brezis. Covered Hahn-Banach Theorems
  (analytic and geometric forms) as well as some orthogonality relations.
* Started reading Nesterov's paper on accelerated gradient. Got stuck
  trying to prove an innequality regarding convex functions with
  Lipschitz gradients, but managed to do it.

## 06.02.23.

* Talked to Yuri, should implement Nesterov Accelerated Gradient before
  going through the article in detail.
* Decided I'm going to track my Functional Analysis progress here. Right
  now I'm at the Open Mapping and Closed Graph theorems.

## 09.02.23.

* Implemented Nesterov Accelerated Gradient algorithm, it is not working.
  Graphs are shet.

## 15.02.23.

* Meeting with Yuri. Nesterov worked after tweaking the learning rate.
  Need to code ML version. Maybe start to write thesis with what we did
  in this problem.

## 28.02.23.

* Still need to implement boost version of Nesterov acceleration.
  Should study papers which address acceleration in stochastic setting.

## 29.03.23.

* I'm back, after a month of struggling with other stuff.
* Next step is to think how to fit the NPIV problem statement into the
  framework of the SIP paper.
* After this, we should take a step back and think about how the proof of
  the main theorem changes when we substitute things we knew exactly (for
  example, the kernel or the operator A) for approximations.
* Meanwhile, read the papers about NPIV to see the kind of things people
  do.



## MFG Project

# 05.02.23.

* Tried to read IMPA's coloquium paper on MFG. Didn't understand shit.
  Need to study Optimal Control Theory, as well as PDEs.

## 05.02.23.

* Just searched a bit for some optimal control references. Evans is not
  that good of a book to study the transport equation. Will talk to Yuri
  tomorrow.

## 06.02.23.

* Talked to Yuri, should study stochastic control.
